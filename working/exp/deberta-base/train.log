max_len: 5121
Using 1 GPUs
Namespace(local_rank=0, opts=[], skip_test=False)
========== fold: 0 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

max_len: 5121
Using 1 GPUs
Namespace(local_rank=0, opts=[], skip_test=False)
========== fold: 0 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

max_len: 5121
Using 1 GPUs
Namespace(local_rank=0, opts=[], skip_test=False)
========== fold: 0 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

max_len: 5121
Using 1 GPUs
Namespace(local_rank=0, opts=[], skip_test=False)
========== fold: 0 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

Using 1 GPUs
Namespace(local_rank=0, opts=[], skip_test=False)
========== fold: 0 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

Epoch 1 - avg_train_loss: 0.1934  avg_val_loss: 0.1122  time: 110s
Epoch 1 - Score: 0.4746  Scores: [0.5085041577328752, 0.4602252488489177, 0.4378286241079554, 0.4615271340392796, 0.5034985199862455, 0.4760076482681672]
Epoch 1 - Save Best Score: 0.4746 Model
Epoch 2 - avg_train_loss: 0.1060  avg_val_loss: 0.1092  time: 110s
Epoch 2 - Score: 0.4681  Scores: [0.4925634679014853, 0.45725916996971955, 0.442710184253288, 0.4547319091352682, 0.49134186936516655, 0.4699762694057249]
Epoch 2 - Save Best Score: 0.4681 Model
Epoch 3 - avg_train_loss: 0.0976  avg_val_loss: 0.1071  time: 109s
Epoch 3 - Score: 0.4634  Scores: [0.4876523076872933, 0.4522262120592954, 0.42479996150238963, 0.4560608003232319, 0.49700953343783255, 0.4626489111353368]
Epoch 3 - Save Best Score: 0.4634 Model
Epoch 4 - avg_train_loss: 0.0912  avg_val_loss: 0.1054  time: 109s
Epoch 4 - Score: 0.4597  Scores: [0.49497044391242184, 0.4526125338128571, 0.4178831433035985, 0.461831950717908, 0.4802104659216432, 0.45091323180235127]
Epoch 4 - Save Best Score: 0.4597 Model
Epoch 5 - avg_train_loss: 0.0865  avg_val_loss: 0.1046  time: 109s
Epoch 5 - Score: 0.4580  Scores: [0.48850417149687814, 0.45359286088165335, 0.42014826455808596, 0.4584995644213532, 0.47447315829704256, 0.45269863136778776]
Epoch 5 - Save Best Score: 0.4580 Model
========== fold: 0 result ==========
Score: 0.4580  Scores: [0.48850417149687814, 0.45359286088165335, 0.42014826455808596, 0.4584995644213532, 0.47447315829704256, 0.45269863136778776]
========== fold: 1 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

Epoch 1 - avg_train_loss: 0.2026  avg_val_loss: 0.1161  time: 109s
Epoch 1 - Score: 0.4831  Scores: [0.5067981534464925, 0.4603478938375867, 0.4347990995666999, 0.47768356126878136, 0.5304677080332473, 0.48849481766523817]
Epoch 1 - Save Best Score: 0.4831 Model
Epoch 2 - avg_train_loss: 0.1133  avg_val_loss: 0.1100  time: 109s
Epoch 2 - Score: 0.4700  Scores: [0.5061602243070119, 0.4537108370701425, 0.4304740356455548, 0.4647260126667254, 0.5084147809854697, 0.45656708388183237]
Epoch 2 - Save Best Score: 0.4700 Model
Epoch 3 - avg_train_loss: 0.1059  avg_val_loss: 0.1102  time: 110s
Epoch 3 - Score: 0.4702  Scores: [0.5088200435923035, 0.46019823133978965, 0.4284203100782434, 0.4636005390535115, 0.5078497458371068, 0.45234953267545175]
Epoch 4 - avg_train_loss: 0.0996  avg_val_loss: 0.1068  time: 109s
Epoch 4 - Score: 0.4631  Scores: [0.4932512769614286, 0.45117589309742306, 0.42505959122171827, 0.46503357761221664, 0.4929052179922561, 0.4512372229182173]
Epoch 4 - Save Best Score: 0.4631 Model
Epoch 5 - avg_train_loss: 0.0960  avg_val_loss: 0.1075  time: 109s
Epoch 5 - Score: 0.4646  Scores: [0.4933968689460034, 0.45382529863862686, 0.425420075100836, 0.46830288715958845, 0.49265416861460426, 0.4542007825078991]
========== fold: 1 result ==========
Score: 0.4631  Scores: [0.4932512769614286, 0.45117589309742306, 0.42505959122171827, 0.46503357761221664, 0.4929052179922561, 0.4512372229182173]
========== fold: 2 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

Epoch 1 - avg_train_loss: 0.1948  avg_val_loss: 0.1230  time: 110s
Epoch 1 - Score: 0.4983  Scores: [0.5122075906129564, 0.4925107856655555, 0.4825060986400235, 0.48138651734154664, 0.5083238414069294, 0.5130876070098818]
Epoch 1 - Save Best Score: 0.4983 Model
Epoch 2 - avg_train_loss: 0.1041  avg_val_loss: 0.1084  time: 110s
Epoch 2 - Score: 0.4672  Scores: [0.4929695281016155, 0.4537090095713655, 0.42805190158646145, 0.4719612819992984, 0.4917445432888072, 0.46455049444935115]
Epoch 2 - Save Best Score: 0.4672 Model
Epoch 3 - avg_train_loss: 0.0986  avg_val_loss: 0.1076  time: 110s
Epoch 3 - Score: 0.4652  Scores: [0.48875661332415127, 0.45109932582952483, 0.42469583340172884, 0.47113563962200766, 0.49442465656257445, 0.4613585579876498]
Epoch 3 - Save Best Score: 0.4652 Model
Epoch 4 - avg_train_loss: 0.0943  avg_val_loss: 0.1078  time: 109s
Epoch 4 - Score: 0.4657  Scores: [0.4893610078708471, 0.4506187735573148, 0.42411632446049613, 0.4710114793723758, 0.4979123249661609, 0.46093141236862406]
Epoch 5 - avg_train_loss: 0.0927  avg_val_loss: 0.1076  time: 110s
Epoch 5 - Score: 0.4652  Scores: [0.4879009499921353, 0.4504631093522954, 0.4235979736811145, 0.4701744110399184, 0.497049301046387, 0.4620588259499646]
Epoch 5 - Save Best Score: 0.4652 Model
========== fold: 2 result ==========
Score: 0.4652  Scores: [0.4879009499921353, 0.4504631093522954, 0.4235979736811145, 0.4701744110399184, 0.497049301046387, 0.4620588259499646]
========== fold: 3 training ==========
DebertaConfig {
  "_name_or_path": "microsoft/deberta-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "c2p",
    "p2c"
  ],
  "position_biased_input": false,
  "relative_attention": true,
  "transformers_version": "4.24.0",
  "type_vocab_size": 0,
  "vocab_size": 50265
}

Epoch 1 - avg_train_loss: 0.2025  avg_val_loss: 0.1217  time: 110s
Epoch 1 - Score: 0.4949  Scores: [0.5223005557182393, 0.48540532488178445, 0.45860368679665664, 0.4628464970701799, 0.5024802543575175, 0.5379269165647355]
Epoch 1 - Save Best Score: 0.4949 Model
Epoch 2 - avg_train_loss: 0.1111  avg_val_loss: 0.1047  time: 111s
Epoch 2 - Score: 0.4589  Scores: [0.48326262477282855, 0.44866343971204903, 0.42825369824822085, 0.4535929106533151, 0.48126023011452834, 0.45825454099125307]
Epoch 2 - Save Best Score: 0.4589 Model
Epoch 3 - avg_train_loss: 0.1040  avg_val_loss: 0.1083  time: 111s
Epoch 3 - Score: 0.4669  Scores: [0.4818998512759515, 0.4536075210419887, 0.43488532969640914, 0.47906899183579155, 0.49619686667113905, 0.45591231458629017]
Epoch 4 - avg_train_loss: 0.0961  avg_val_loss: 0.1039  time: 111s
Epoch 4 - Score: 0.4570  Scores: [0.4810878837716188, 0.44990805281637597, 0.42380721232351687, 0.4622274799997661, 0.48312109103480705, 0.4416173033397807]
Epoch 4 - Save Best Score: 0.4570 Model
Epoch 5 - avg_train_loss: 0.0922  avg_val_loss: 0.1027  time: 111s
Epoch 5 - Score: 0.4542  Scores: [0.48108238431909384, 0.44805644645840037, 0.4218633351135094, 0.45236622551400435, 0.4826729892111552, 0.4391023089941403]
Epoch 5 - Save Best Score: 0.4542 Model
========== fold: 3 result ==========
Score: 0.4542  Scores: [0.48108238431909384, 0.44805644645840037, 0.4218633351135094, 0.45236622551400435, 0.4826729892111552, 0.4391023089941403]
========== CV ==========
Score: 0.4602  Scores: [0.4877025681272735, 0.4508263079156672, 0.4226706952302871, 0.4615663475218518, 0.4868535435569374, 0.45134808654359654]
